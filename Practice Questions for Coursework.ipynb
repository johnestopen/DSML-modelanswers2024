{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9c0b94b",
   "metadata": {},
   "source": [
    "## Practice Questions\n",
    "\n",
    "This notebook contains practise questions for the assess coursework on the 19th of March. I will upload some model answers in a later lecture. If you can answer all of these questions, then you shouldn't have too much trouble in the coursework.\n",
    "\n",
    "Please use the ‘litho_log’ data available in the data folder of this repository to complete these exercises.\n",
    "\n",
    "### Exercise 1 (Approx. 15 mins)\n",
    "\n",
    "You have been given some data that contains a large number of observations of downhole logs and the name of the lithologies associated with the log response.\n",
    " - 'DEPTH_WMSF': the depth of the measurement below seafloor \n",
    " - 'HCGR': Total gamma ray counts \n",
    " - 'HFK': Potassium counts \n",
    " - 'HTHO': Thorium counts \n",
    " - 'HURA': Uranium counts \n",
    " - 'IDPH': Deep Phasor Dual Induction–Spherically Focused Resistivity \n",
    " - 'IMPH': Medium Phasor Dual Induction–Spherically Focused Resistivity \n",
    " - 'SFLU': Shallow Phasor Dual Induction–Spherically Focused Resistivity \n",
    " - 'lithology': our target value, a string representing the name of the lithology\n",
    " \n",
    "Using a Markdown cell, describe the steps that you would take to clean this data and prepare it for machine learning analysis."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f935aa68",
   "metadata": {},
   "source": [
    "### Write your answer here (in this Markdown cell)\n",
    "\n",
    "# ANSWER\n",
    "1. Open and read the dataset using pd.read_csv() function.\n",
    "2. Drop the duplicates using drop_duplicates() function.\n",
    "3. Split the data into features and target variables.\n",
    "    - X contains the features, y contains the target variable.\n",
    "4. Do a train test split, using train_test_split() function and a reasonable train size\n",
    "5. Search for outliers and deal with them using domain knowledge\n",
    "    - Make changes to both x-train and x-test, only after splitting so you don't know what your test set looks like\n",
    "6. Impute any missing values\n",
    "    - Use the SimpleImputer() function to fill in missing values\n",
    "7. Scale the data\n",
    "    - Use the StandardScaler() function to scale the data\n",
    "8. The steps 6 and 7 can be done using a pipeline\n",
    "9. encode the target variable\n",
    "    - Use the LabelEncoder() function to encode the target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376257ae",
   "metadata": {},
   "source": [
    "### Exercise 2 (25 minutes)\n",
    "\n",
    "Load the data set and drop any duplicates you find.\n",
    "\n",
    "Then answer the following questions:\n",
    "\n",
    " - What is the distribution of the lithologies in this dataset?\n",
    " - What is the average depth of the interbedded clay and mud?\n",
    " - Among the samples found at or below 400m (below seafloor), what are the characteristics of the samples with the five highest Uranium counts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e764111",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('Data/litho_log_data.csv') # load and read\n",
    "\n",
    "data.drop_duplicates(inplace=True) # drop duplicates\n",
    "\n",
    "data['lithology'].value_counts() # count the number of unique values in the lithology column and see their distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18032af",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['lithology'] == 'Interbedded clay and mud']['DEPTH_WMSF'].mean() # average depth of interbedded clay and mud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b961701",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['DEPTH_WMSF'] >= 400] # samples below 400m\n",
    "\n",
    "#now sort this data by uranium counts\n",
    "data[data['DEPTH_WMSF'] >= 400].sort_values(by'HURA', ascending=False) # sort the data by uranium counts\n",
    "\n",
    "# now show the characteristics of the top 5\n",
    "data[data['DEPTH_WMSF'] >= 400].sort_values(by'HURA', ascending=False).head(5) # show the top 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4483fc99",
   "metadata": {},
   "source": [
    "### Exercise 3.1 (10 minutes)\n",
    "\n",
    "Using the steps you outlined in Exercise 1, split this dataset into a training set and a testing set (with reasonable names). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4b33b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Data/litho_log_data.csv') # load and read\n",
    "\n",
    "data.drop_duplicates(inplace=True) # drop duplicates\n",
    "\n",
    "# y target variable = 'lithology'\n",
    "# X features = all columns except 'lithology'\n",
    "\n",
    "X = data.drop(columns = 'lithology')\n",
    "y = data['lithology']\n",
    "\n",
    "# encode\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(y) # fit the encoder and transform the dataset of the target variable\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Split the data into training and test sets (80% training, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) # Random state for reproducibility\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c667819",
   "metadata": {},
   "source": [
    "### Exercise 3.2 (20 minutes)\n",
    "\n",
    "Examine the training set. Are there any missing or unusual values in any of the columns? What are these values and in which columns can they be found? Use a Markdown cell to describe your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67cd44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now examine training set using .describe()\n",
    "X_train.describe()\n",
    "# This was not usefulm so a graphical approach is used instead\n",
    "X_train.hist(bins=50, figsize=(20,15))\n",
    "# Outliers are seen in IDPH, IMPH, and SFLU, as you can see from .describe() also\n",
    "# Now using a box and whisker plot to see the outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b547d7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.boxplot(data=X_train[['IDPH', 'IMPH', 'SFLU']])\n",
    "# this shows the whole range of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c5d7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now use ylim to only see between 0 and 5\n",
    "sns.boxplot(data=X_train[['IDPH', 'IMPH', 'SFLU']])\n",
    "plt.ylim(0, 5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a88887c9",
   "metadata": {},
   "source": [
    "Ask the data provider what these mean, if they are on purpose or if they are really not supposed to be there. If they are not supposed to be there, then you should remove them.\n",
    "Some outliers may not be errors, but may be real data. You should use your domain knowledge to decide what to do with them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fcdd4d",
   "metadata": {},
   "source": [
    "## Exercise 3.3 (10 minutes)\n",
    "\n",
    "Replace any unusual values with `np.nan`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3a2299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now replace any values we deemed outliers using a lambda function\n",
    "X_train[['IDPH', 'IMPH', 'SFLU']]=X_train[['IDPH', 'IMPH', 'SFLU']].apply(lambda x: where np.where (x == 1950, np.nan, x))\n",
    "\n",
    "# also do this for the test\n",
    "X_test[['IDPH', 'IMPH', 'SFLU']]=X_test[['IDPH', 'IMPH', 'SFLU']].apply(lambda x: where np.where (x == 1950, np.nan, x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b7f304",
   "metadata": {},
   "source": [
    "## Exercise 4 (30 mins)\n",
    "\n",
    "Create a pipeline with an `Imputer`, a `Scaler`, and a `DecisionTreeClassifier`. Set the `random_state` of the `DecisionTreeClassifier` to 42.\n",
    "\n",
    "Create and run a RandomizedSearchCV on three hyperparameters of your choice using `accuracy` as the metric of choice (use `n_iter = 20`). Explain what varying each of your selected hyperparameters will do to your model.\n",
    "\n",
    "Print out the accuracy and parameters of your best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b9e98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from skelearn.pipeline import Pipeline\n",
    "from skelearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Create a pipeline, using random state 42\n",
    "dt_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('classifier', DecisionTreeClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Run a randomised search CV\n",
    "# hyperparameters that i want to test ==== search online for the best hyperparameters for each c v\n",
    "param_grid = {\n",
    "    'dt_model__maxfeatures': [i for i in range(2,9)],\n",
    "    'dt_model__max_depth': [i for i in range(4,11)],\n",
    "    'dt_model__min_samples_split': [i for i in range(1,21)]\n",
    "}\n",
    "\n",
    "# ORRRRR\n",
    "# BUT USE REASONABLE VALUES FOR THE PARAMS\n",
    "param_grid = {\n",
    "    'dt_model__maxfeatures': randint(4,40),\n",
    "    'dt_model__max_depth': [i for i in range(4,11)], # max depth indicates the maximum depth of the tree\n",
    "    'dt_model__min_samples_split': [i for i in range(1,21)]\n",
    "}\n",
    "\n",
    "dt_search = RandomizedSearchCV(\n",
    "    dt_pipeline,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=20, # number of iterations is good to be 20 to 30\n",
    "    n_jobs=1,\n",
    "    verbose = 5, # how much information you want to see when it is running and printed into terminal\n",
    "    random_state=42 # for reproducibility\n",
    "    scoring='accuracy'\n",
    ")\n",
    "\n",
    "dt_search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43c154e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print accuracy and parameters of best model\n",
    "dt_search.best_score_\n",
    "# This shows the accuracy\n",
    "# Now show the best parameters\n",
    "dt_search.best_params_\n",
    "# OR\n",
    "dt_search.best_estimator_\n",
    "# in additon cv_results_ can be used to see the results of the search\n",
    "pd.DataFrame(dt_search.cv_results_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01fa47d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "803c55f2",
   "metadata": {},
   "source": [
    "## Exercise 5 (10 mins)\n",
    "\n",
    "Explain why accuracy may not be the best metric for assessing the performance of a classifier model.\n",
    "\n",
    "Describe three other classification metrics and the scenarios in which they would be useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8dbea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imbalanced dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aefb1a2c",
   "metadata": {},
   "source": [
    "Conceptual question\n",
    "- Recall the metrics\n",
    "\n",
    "# Metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
